{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5dccb83-3a1a-4c3d-8928-68367055cd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import seaborn as sns\n",
    "import random\n",
    "# import cv2\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63a7446e-a6bd-435b-979d-6e18890945c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/ltarricone/ml4h_data/project1/chest_xray/chest_xray\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a61798ac-3aa0-4524-b6a5-0714d2dfe42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageFolder(data_dir+'/train', \n",
    "                      transform=T.Compose([T.Resize(260),                                     #to shrink down the image\n",
    "                                            T.CenterCrop(224),                                 #to match the size of ResNet and at the same crop out the outside of the image \n",
    "                                            T.RandomHorizontalFlip(),                          #because we don't want a left-right bias\n",
    "                                            T.RandomRotation(10),                              #to have rotational invariance features\n",
    "                                            T.ToTensor(),                                       #because the model takes torch.Tensors as input\n",
    "                                           # T.Normalize(mean=[0.485, 0.456, 0.406],           #to match the standardization of \n",
    "                                            #std=[0.229, 0.224, 0.225] ,inplace=True)\n",
    "                                           ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d76ac772-ace4-432e-bc72-bd3f0a4842e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4173, 1043)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = round(len(dataset)*0.8) # 80%\n",
    "val_size = len(dataset) - train_size # 20%\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a28c238-5d7e-4dd3-916b-5cc295a7d715",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=1, pin_memory=True)\n",
    "val_dl = DataLoader(val_ds, batch_size*2, num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ea8f47a-0d1c-45c6-8843-8acfdadb9c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set device\n",
    "device = torch.device('cuda')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03ff8d5f-9f8e-41d9-a49c-b45ebfae6e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "    \n",
    "    \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield self.to_device(b, self.device) # yield will stop here, perform other steps, and the resumes to the next loop/batch\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)\n",
    "\n",
    "    def to_device(self, data, device):\n",
    "        \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "        if isinstance(data, (list,tuple)):\n",
    "            return [to_device(x, device) for x in data]\n",
    "        return data.to(device, non_blocking=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f58df6b-e76b-4b40-8948-b88ac91cfd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af3f3992-f0fb-479c-bb51-aa0f54cf4453",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to calculate the performance of the model\n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1) \n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds)), preds\n",
    "\n",
    "def F1_score(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1) \n",
    "    \n",
    "    # precision, recall, and F1\n",
    "    cm  = confusion_matrix(labels, preds)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    f1 = 2*((precision*recall)/(precision+recall))\n",
    "    \n",
    "    return precision,recall,f1,preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d3aa1c4-5e07-46c3-931e-a37d01585515",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PneumoniaModelBase(nn.Module):\n",
    "    \"\"\"\n",
    "    Base class that will have all the useful methods for the training of the model\n",
    "    \"\"\"\n",
    "    \n",
    "    # this is for loading the batch of train image and outputting its loss, accuracy \n",
    "    # & predictions\n",
    "    def training_step(self, batch, weight):\n",
    "        images,labels = batch\n",
    "        labels2 = torch.round(torch.rand(labels.shape)).to(device).long()\n",
    "        out = self(images)                                      # generate predictions\n",
    "        loss = F.cross_entropy(out, labels2, weight=weight)      # weighted compute loss\n",
    "        acc,preds = accuracy(out, labels)                       # calculate accuracy\n",
    "        \n",
    "        return {'train_loss': loss, 'train_acc':acc}\n",
    "       \n",
    "    # this is for computing the train average loss and acc for each epoch\n",
    "    def train_epoch_end(self, outputs):\n",
    "        batch_losses = [x['train_loss'] for x in outputs]       # get all the batches loss\n",
    "        epoch_loss = torch.stack(batch_losses).mean()           # combine losses\n",
    "        batch_accs = [x['train_acc'] for x in outputs]          # get all the batches acc\n",
    "        epoch_acc = torch.stack(batch_accs).mean()              # combine accuracies\n",
    "        \n",
    "        return {'train_loss': epoch_loss.item(), 'train_acc': epoch_acc.item()}\n",
    "    \n",
    "    # this is for loading the batch of val/test image and outputting its loss, accuracy, \n",
    "    # predictions & labels\n",
    "    def validation_step(self, batch):\n",
    "        images,labels = batch\n",
    "        out = self(images)                                      # generate predictions\n",
    "        loss = F.cross_entropy(out, labels)                     # compute loss\n",
    "        acc,preds = accuracy(out, labels)                       # calculate acc & get preds\n",
    "        \n",
    "        return {'val_loss': loss.detach(), 'val_acc':acc.detach(), \n",
    "                'preds':preds.detach(), 'labels':labels.detach()}\n",
    "    # detach extracts only the needed number, or other numbers will crowd memory\n",
    "    \n",
    "    # this is for computing the validation average loss and acc for each epoch\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]         # get all the batches loss\n",
    "        epoch_loss = torch.stack(batch_losses).mean()           # combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]            # get all the batches acc\n",
    "        epoch_acc = torch.stack(batch_accs).mean()              # combine accuracies\n",
    "        \n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "\n",
    "    # this is for printing out the results after each epoch\n",
    "    def epoch_end(self, epoch, train_result, val_result):\n",
    "        print('Epoch [{}], train_loss: {:.4f}, train_acc: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}'.\n",
    "              format(epoch+1, train_result['train_loss'], train_result['train_acc'],\n",
    "                     val_result['val_loss'], val_result['val_acc']))\n",
    "    \n",
    "    # this is for using on the test set, it outputs the average loss and acc, \n",
    "    # and outputs the predictions\n",
    "    def test_prediction(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()           # combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()              # combine accuracies\n",
    "        # combine predictions\n",
    "        batch_preds = [pred for x in outputs for pred in x['preds'].tolist()] \n",
    "        # combine labels\n",
    "        batch_labels = [lab for x in outputs for lab in x['labels'].tolist()]  \n",
    "        \n",
    "        return {'test_loss': epoch_loss.item(), 'test_acc': epoch_acc.item(),\n",
    "                'test_preds': batch_preds, 'test_labels': batch_labels}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72578981-1525-48ba-aa82-5d8b9c83238f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ltarricone/jupyter/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#downloading ResNet50\n",
    "resnet50 = models.resnet50(weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e0fdd5d-7bcf-4387-9c93-079d72537e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PneumoniaResnet(PneumoniaModelBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Use a pretrained model\n",
    "        self.network = models.resnet50(weights=True)\n",
    "        # Freeze training for all layers before classifier\n",
    "        for param in self.network.fc.parameters():\n",
    "            param.require_grad = False  \n",
    "        num_features = self.network.fc.in_features # get number of in features of last layer\n",
    "        self.network.fc = nn.Linear(num_features, 2) # replace model classifier\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fae8f30-49d2-4f48-9177-5d359b942dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, weight, \n",
    "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
    "    torch.cuda.empty_cache() # release all the GPU memory cache\n",
    "    history = {}\n",
    "    \n",
    "#    Set up cutom optimizer with weight decay\n",
    "#    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
    "\n",
    "#     Set up one-cycle learning rate scheduler\n",
    "#     sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n",
    "#                                                 steps_per_epoch=len(train_loader))\n",
    "#   sched = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    \n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "\n",
    "    best_loss = 1 # initialize best loss, which will be replaced with lower better loss\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Training Phase \n",
    "        model.train() \n",
    "        train_outputs = []      \n",
    "        lrs = []\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            outputs = model.training_step(batch, weight)\n",
    "            loss = outputs['train_loss']                          # get the loss\n",
    "            train_outputs.append(outputs)\n",
    "            # get the train average loss and acc for each epoch\n",
    "            train_results = model.train_epoch_end(train_outputs)                        \n",
    "            loss.backward()                                       # compute gradients\n",
    "            \n",
    "            # Gradient clipping\n",
    "            if grad_clip: \n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "            \n",
    "            optimizer.step()                                      # update weights\n",
    "            optimizer.zero_grad()                                 # reset gradients  \n",
    "            \n",
    "#             Record & update learning rate\n",
    "#             lrs.append(get_lr(optimizer))\n",
    "#             sched.step()\n",
    "        \n",
    "        # Validation phase\n",
    "        val_results = evaluate(model, val_loader)\n",
    "        \n",
    "        # Save best loss\n",
    "        if val_results['val_loss'] < best_loss:\n",
    "            best_loss = min(best_loss, val_results['val_loss'])\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            #torch.save(model.state_dict(), 'best_model.pt')\n",
    "        \n",
    "        # print results\n",
    "        model.epoch_end(epoch, train_results, val_results)\n",
    "        \n",
    "        # save results to dictionary\n",
    "        to_add = {'train_loss': train_results['train_loss'],\n",
    "                  'train_acc': train_results['train_acc'],\n",
    "                 'val_loss': val_results['val_loss'],\n",
    "                  'val_acc': val_results['val_acc'], 'lrs':lrs}\n",
    "        \n",
    "        # update performance dictionary\n",
    "        for key,val in to_add.items():\n",
    "            if key in history:\n",
    "                history[key].append(val)\n",
    "            else:\n",
    "                history[key] = [val]\n",
    "                \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    model.load_state_dict(best_model_wts)                         # load best model\n",
    "    \n",
    "    return history, optimizer, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a89115e1-7722-4c82-8829-806e3ec8a831",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "val_dl = DeviceDataLoader(val_dl, device)\n",
    "\n",
    "model = to_device(PneumoniaResnet(), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "935a5c79-f077-4486-b2dd-d39727b4a13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "lr = 0.0001\n",
    "grad_clip = None\n",
    "weight_decay = 1e-4\n",
    "opt_func = torch.optim.Adam\n",
    "# weighted loss for data class imbalance\n",
    "weight = torch.FloatTensor([3876/(1342+3876), 1342/(1342+3876)]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcce8f5-e3a7-4683-b1d9-0d799f97e31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], train_loss: 0.6177, train_acc: 0.2854, val_loss: 1.1448, val_acc: 0.2579\n"
     ]
    }
   ],
   "source": [
    "history, optimizer, best_loss = fit(epochs, lr, model, train_dl, val_dl, weight, \n",
    "                                    grad_clip=grad_clip, \n",
    "                                    weight_decay=weight_decay, \n",
    "                                    opt_func=opt_func)\n",
    "\n",
    "print('Best loss is:', best_loss)\n",
    "\n",
    "bestmodel = {'model': PneumoniaResnet(),\n",
    "              'state_dict': model.state_dict(),\n",
    "              'optimizer' : optimizer.state_dict()}\n",
    "\n",
    "torch.save(bestmodel, 'PneumoniaResnet_random.pth')\n",
    "\n",
    "# Plot Accuracy and Loss \n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "t = f.suptitle('Performance', fontsize=12)\n",
    "f.subplots_adjust(top=0.85, wspace=0.3)\n",
    "\n",
    "epoch_list = list(range(1,epochs+1))\n",
    "ax1.plot(epoch_list, history['train_acc'], label='Train Accuracy')\n",
    "ax1.plot(epoch_list, history['val_acc'], label='Validation Accuracy')\n",
    "ax1.set_xticks(np.arange(0, epochs+1, 5))\n",
    "ax1.set_ylabel('Accuracy Value')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_title('Accuracy')\n",
    "l1 = ax1.legend(loc=\"best\")\n",
    "\n",
    "ax2.plot(epoch_list, history['train_loss'], label='Train Loss')\n",
    "ax2.plot(epoch_list, history['val_loss'], label='Validation Loss')\n",
    "ax2.set_xticks(np.arange(0, epochs+1, 5))\n",
    "ax2.set_ylabel('Loss Value')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_title('Loss')\n",
    "l2 = ax2.legend(loc=\"best\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
